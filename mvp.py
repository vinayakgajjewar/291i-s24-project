# -*- coding: utf-8 -*-
"""mvp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10QH_ZntDXCA6u51D83RIlks82U34OPrz
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install autogluon

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split
import plotly.express as px
import plotly.graph_objs as go
from google.colab import files
from autogluon.tabular import TabularDataset, TabularPredictor

# This is the path to the self-reported motion sickness scores.
scoresp = "drive/MyDrive/CS291I/SelfReportData"

# This is where we'll look for the intermediate per-game data we generate.
pergamep = "drive/MyDrive/CS291I/gamedata"

# Each key is the string we'll use to find user-reported sickness data, and each
# value is the path to the game engine data for that game.
gamedirs = {
    'Beat Saber': 'drive/MyDrive/CS291I/Beat_saber',
    'Cartoon Network Journeys VR': 'drive/MyDrive/CS291I/Carton_Network',
    'Epic Roller Coasters': 'drive/MyDrive/CS291I/Epic RollerCoaster',
    'Mini Motor Racing X': 'drive/MyDrive/CS291I/Mini_Racing',
    'Traffic Cop': 'drive/MyDrive/CS291I/Traffic_Cop',
    'Voxel Shot VR': 'drive/MyDrive/CS291I/Voxel_Shot_VR',
    'VR Rome': 'drive/MyDrive/CS291I/VR_ROME',
    'Monster Awakens': 'drive/MyDrive/CS291I/Monster_awaken'
}

# Get all the game-related CSV file names for a particular game in one place.
def getfiles(gamesp):
  allfiles = []
  for root, dirs, files in os.walk(gamesp):
    for file in files:
      if file.startswith('.'): continue
      allfiles.append(os.path.join(root, file))
  return allfiles

# Each key is the game name, and the associated value is a list of all game
# engine data files associated with that game.
allfiles = {}
for k, v in gamedirs.items():
  allfiles[k] = getfiles(v)
print(allfiles)

# Get the frame number from a given timestamp. I don't really understand this,
# but I trust that it works.
def getframe(csvfile, time, gamename, filelist):
  participant = csvfile.split(' ')[1]
  for file in filelist:
    if gamename in file and participant in file and 'control.csv' in file:
      ctrldata = pd.read_csv(file)
      timescol = ctrldata['timestamp']
      rownum = np.argmin(np.abs(timescol - time))
      framecol = ctrldata['framecounter']
      framenum = framecol[rownum]
      #print(framenum)
      return framenum

def getscore(csvfile, gamename, filelist):
  scores = []
  frames = []
  df = pd.read_csv(csvfile, header=None)
  for index, row in df.iterrows():
    scores.append(row.iloc[1])
    rawts = row.iloc[0]
    frames.append(getframe(csvfile, rawts / 1000, gamename, filelist))
  return scores, frames

# Get score data for a particular game.
def getdf(gamename, scoresp, gamedir):
  parts = []
  ascores = []
  aframes = []
  scoresdf = pd.DataFrame()
  for filename in os.listdir(scoresp):
    if not filename.startswith(".") and filename.endswith(".csv") and gamename in filename:
      partid = filename.split(' ')[0]
      parts.append(partid)
      scores, frames = getscore(scoresp + "/" + filename, gamedir.split('/')[3], allfiles[gamename])
      if (frames[0] != None):
        aframes.extend(frames)
        ascores.extend(scores)
      scoredf = pd.DataFrame({"score": scores, "framecounter": frames})

      # Workaround for the Mini Motor Racing X file names.
      if gamename == "Mini Motor Racing X":
        partstr = filename.split(' ')[1]
      else:
        partstr = "P" + str(partid)
      scoredf["participant"] = partstr
      scoresdf = pd.concat([scoresdf, scoredf])
    else: continue
  return scoresdf

allscore = pd.DataFrame()
for k, v in gamedirs.items():
  scoresdf = getdf(k, scoresp, v)
  scoresdf["game"] = k
  allscore = pd.concat([allscore, scoresdf])
allscore.head()

# Let's see how many unique participants there are for the self-report data.
# Note that the Mini Motor Racing X participant IDs are going to look different
# because the only constant in life is suffering.
print(allscore["participant"].unique())

# Get in-game camera data for a single game.
def getcam(filelist):
  cameradf = pd.DataFrame()
  for file in filelist:
    if 'camera.csv' not in file: continue
    df = pd.read_csv(file)
    df['participant'] = file.split('/')[4].split(' ')[0]
    cameradf = pd.concat([cameradf, df])
  return cameradf

cameradf = pd.DataFrame()
for k, v in gamedirs.items():
  camdf = getcam(allfiles[k])
  camdf['game'] = k
  cameradf = pd.concat([cameradf, camdf])
cameradf.head()

# Print all unique camera names across all games.
print(cameradf['name'].unique())

# I also want to see the unique participants.
print(cameradf['participant'].unique())

# Mwahaha let's throw some pose.csv into the mix!
def getpose(gamename):
  posedf = pd.DataFrame()
  for file in allfiles[gamename]:
    if 'pose.csv' not in file: continue
    df = pd.read_csv(file)
    df['participant'] = file.split('/')[4].split(' ')[0]
    posedf = pd.concat([posedf, df])
  return posedf

posedf = pd.DataFrame()
for k, v in gamedirs.items():
  df = getpose(k)
  df['game'] = k
  posedf = pd.concat([posedf, df])
posedf.head()

# It's time for the moment of truth. We'll merge cameradf and scoresdf and see
# what we can do with it.

print(cameradf)
print(allscore)
print(allscore['game'].unique())
cameradf = cameradf.merge(right=allscore, on=['participant', 'framecounter', 'game'])

# Hee hoo let's throw posedf in there too.
cameradf = cameradf.merge(right=posedf, on=['participant', 'framecounter', 'game'])

cameradf.head()

cameradf.describe().transpose()

# Define a helper function to convert those matrix strings into actual matrices.
def str2mat(strmat):
  mat = np.array([float(num) for num in strmat.split()])
  return mat.reshape(4, 4)

# Helper functions for dealing with projection and view matrices.

# Calculate field of view (FOV) from a projection matrix. This function returns
# FOV in degrees, not radians.
def getfov(projmat):
  yfov = 2.0 * np.arctan(1.0 / projmat[1][1])
  aspectr = projmat[1][1] / projmat[0][0]
  xfov = 2.0 * np.arctan(np.tan(yfov / 2.0) * aspectr)
  xfovdeg = np.degrees(xfov)
  yfovdeg = np.degrees(yfov)
  return xfovdeg, yfovdeg, aspectr

# Determine if a given project matrix represents a perspective projection or an
# orthographic projection.
def ispersp(row):
  projmat = row["projection"]
  return projmat[3][3] == 0.0 and projmat[2][3] != 0.0
def isortho(row):
  projmat = row["projection"]
  return projmat[3][3] == 1.0 and projmat[2][3] == 0.0

# Extract a bunch of information from a given projection matrix.
def projdcmp(row):
  projmat = str2mat(row["projection"])
  near = projmat[2][3] / (projmat[2][2] - 1.0)
  far = projmat[2][3] / (projmat[2][2] + 1.0)
  xfovdeg, yfovdeg, aspectr = getfov(projmat)
  return pd.Series([near, far, xfovdeg, yfovdeg, aspectr], index=["near",
                                                                  "far",
                                                                  "xfovdeg",
                                                                  "yfovdeg",
                                                                  "aspectr"])

# Extract a bunch of information from a given view matrix.
def viewdcmp(row):
  viewmat = str2mat(row["view"])
  position = viewmat[:3, 3]
  rotation = viewmat[:3, :3]
  forward = -viewmat[:3, 2]
  up = viewmat[:3, 2]
  return pd.Series([position, rotation, forward, up], index=["position",
                                                             "rotation",
                                                             "forward",
                                                             "up"])

# This is just a wrapper around str2mat because I am lazy. TODO TODO TODO
def velocity(row):
  mat = np.array([float(num) for num in row["velocity"].split()])
  return pd.Series(mat.flatten(), index=["v1", "v2", "v3"])

def angular(row):
  mat = np.array([float(num) for num in row["angularVelocity"].split()])
  #mat = mat.reshape(3, 3)
  return pd.Series(mat.flatten(), index=["a1", "a2", "a3"])

# Convert a 3x3 rotation matrix into a unit quaternion.
def rot2quat(rot):
  w = np.sqrt(1 + rot[0, 0] + rot[1, 1] + rot[2, 2]) / 2
  x = (rot[2, 1] - rot[1, 2]) / (4 * w)
  y = (rot[0, 2] - rot[2, 0]) / (4 * w)
  z = (rot[1, 0] - rot[0, 1]) / (4 * w)
  return np.array([w, x, y, z])

# A wrapper function around rot2quat that we can apply to DF rows.
def r2qwrap(row):
  quat = rot2quat(row["rotation"])
  return pd.Series(quat.flatten(), index=["rotquatw",
                                          "rotquatx",
                                          "rotquaty",
                                          "rotquatz"])

# Let's use our helper functions to add some useful features to cameradf.
cameradf[["near", "far", "xfovdeg", "yfovdeg", "aspectr"]] = cameradf.apply(projdcmp, axis=1)
cameradf[["position", "rotation", "forward", "up"]] = cameradf.apply(viewdcmp, axis=1)
cameradf[["v1", "v2", "v3"]] = cameradf.apply(velocity, axis=1)
cameradf[["a1", "a2", "a3"]] = cameradf.apply(angular, axis=1)

# Add the quaternion representation of the rotation matrix.
cameradf[["rotquatw", "rotquatx", "rotquaty", "rotquatz"]] = cameradf.apply(r2qwrap, axis=1)

cameradf.tail()

# Let's see some statistics about sickness score before doing fancy analysis.
def stats(df, column):
  print(column)
  print("\tmin\t", df[column].min())
  print("\tmax\t", df[column].max())
  print("\tmean\t", df[column].mean())
  print("\tstd dev\t", df[column].std())

stats(cameradf, "score")

# We also want some FOV information about this game.
camtypes = cameradf["name"].unique()
for camtype in camtypes:
  print(camtype)
  stats(cameradf[cameradf["name"] == camtype], "xfovdeg")
  stats(cameradf[cameradf["name"] == camtype], "yfovdeg")
  stats(cameradf[cameradf["name"] == camtype], "score")

# Before we do anything crazy, let's clean up cameradf by getting rid of the
# columns we don't care about and decomposing the matrix features into their own
# columns.
# TODO I should turn this into a function so that I can do it to multiple DFs.

cameradf[["pos1", "pos2", "pos3"]] = pd.DataFrame(cameradf["position"].to_list())
cameradf.drop("position", axis=1, inplace=True)

cameradf[["forward1", "forward2", "forward3"]] = pd.DataFrame(cameradf["forward"].to_list())
cameradf.drop("forward", axis=1, inplace=True)

cameradf[["up1", "up2", "up3"]] = pd.DataFrame(cameradf["up"].to_list())
cameradf.drop("up", axis=1, inplace=True)

rotvals = cameradf["rotation"].apply(lambda x: pd.Series(x.flatten()))
rotvals.columns = [f"rot{i}" for i in range(9)]
cameradf = pd.concat([cameradf.drop("rotation", axis=1), rotvals], axis=1)

cameradf.drop("velocity", axis=1, inplace=True)
cameradf.drop("angularVelocity", axis=1, inplace=True)

# TODO verify that we don't actually need these
cameradf.drop("timestamp_x", axis=1, inplace=True)
cameradf.drop("timestamp_y", axis=1, inplace=True)
cameradf.drop("device_id", axis=1, inplace=True)

# TODO Maybe I should explore this further?
cameradf.drop("deviceToAbsoluteTracking", axis=1, inplace=True)

cameradf.drop("name", axis=1, inplace=True)
cameradf.drop("projection", axis=1, inplace=True)
cameradf.drop("view", axis=1, inplace=True)

cameradf.head()

# Let's do some time series shenanigans. We can start with just plotting stuff.
fig = px.scatter(cameradf,
                 x="framecounter",
                 y="score",
                 color="game",
                 template="plotly_white")
fig.show()

cameradf.drop("framecounter", axis=1, inplace=True)
cameradf.drop("participant", axis=1, inplace=True)
cameradf.drop("game", axis=1, inplace=True)
cameradf.head()

# We have to normalize our data for best results. We'll do min-max normalization
# here.
def mmnormal(df, range=(0, 1)):
  return (df - df.min()) / (df.max() - df.min()) * (range[1] - range[0]) + range[0]

# TODO Don't normalize the score; make it categorical instead.
scores = cameradf['score']
cameradf = mmnormal(cameradf.drop(columns=['score']))
cameradf['score'] = scores
cameradf.head()

# We will also divide what we got into training and testing DFs.
traindf, testdf = train_test_split(cameradf, test_size=0.2, random_state=42, shuffle=True)
traindf.to_csv("train.csv", index=False)
testdf.to_csv("test.csv", index=False)

# Define a function to display the correlation matrix for a DataFrame.
def plotcorr(df):
  corr = df.corr()
  fig = px.imshow(corr,
                  labels=dict(x="Features", y="Features", color="Correlation"),
                  x=corr.columns,
                  y=corr.columns)
  fig.show()

# Give me the correlation matrix for cameradf.
plotcorr(cameradf)

# Display a bar graph of correlations.
def plotbar(df):
  corr = df.corr()
  scorcorr = corr["score"]
  fig = go.Figure(data=[go.Bar(x=scorcorr.index, y=scorcorr.values)])
  fig.show()

plotbar(cameradf)

def scatter(df, var1, var2, colorcol):
  fig = px.scatter(df, x=var1, y=var2, color=colorcol)
  fig.show()

scatter(cameradf, "rot6", "score", "score")

# Now let's use AutoGluon.
predictor = TabularPredictor(label='score', problem_type='multiclass').fit(train_data='train.csv')
predictions = predictor.predict('test.csv')

predictor.evaluate('test.csv', silent=True)

ldrboard = predictor.leaderboard('test.csv')
fig = px.bar(ldrboard, x='model', y='score_test')
fig.show()

fig = px.bar(ldrboard, x='model', y='pred_time_test')
fig.show()

features = predictor.feature_importance('test.csv')
fig = px.bar(features, x=features.index, y='importance')
fig.show()